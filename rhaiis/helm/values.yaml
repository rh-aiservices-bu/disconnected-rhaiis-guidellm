image:
  repository: registry.redhat.io/rhaiis/vllm-cuda-rhel9
  tag: "3.2.0-1752784628"
  pullPolicy: IfNotPresent

model:
  servedModelName: meta-llama-3.1-8B-instruct-quantized.w4a16
  tensorParallelSize: 1
  maxModelLen: 8096
  pvcName: llama-31

resources:
  gpu: 1

service:
  port: 8000
  type: ClusterIP

nameOverride: ""
fullnameOverride: ""